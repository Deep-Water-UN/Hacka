{"cells": [{"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "import geomesa_pyspark \nconf = geomesa_pyspark.configure(jars=['/usr/lib/spark/jars/geomesa-hbase-spark-runtime_2.11-2.1.0-m.2.jar'],\n                                 packages=['geomesa_pyspark','pytz'], \n                                 spark_home='/usr/lib/spark/') \n#setAppName('MyTestApp')\nconf.get('spark.master') # u'yarn'\nfrom pyspark.sql import SparkSession\nspark = ( SparkSession.builder.config(conf=conf).getOrCreate() )\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>111</td><td>application_1599127947832_0112</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-250-1-253.ec2.internal:20888/proxy/application_1599127947832_0112/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-250-1-193.ec2.internal:8042/node/containerlogs/container_1599127947832_0112_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "params = {    \"hbase.zookeepers\": \"hbase.optix-ons-local:2181\",    \"hbase.catalog\": \"ons-historical\" } \nfeature = \"ee\" \nee = ( spark    .read    .format(\"geomesa\")    .options(**params)    .option(\"geomesa.feature\", feature)    .load() )\nee.createOrReplaceTempView(\"ee\")\n", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "df1=spark.sql(\"\"\"select \nmmsi,\ndtg,\nvessel_type_code,\nvessel_type_cargo,\nflag_country,\ndestination,\neta,\ndraught,\nlongitude,\nlatitude,\nsog,\nrot,\nheading,\nnav_status_code,\nnav_status,\nsource,\nlength,\nmessage_type,\nvessel_type_main,\nvessel_type_sub,\neeid\n            from ee where \n           st_intersects(position,st_makeBox2d(st_point(-46.4816,-24.1178),st_point(-46.1763,-23.8787))) AND\n           dtg >= cast('2020-01-01 00:00' as timestamp) and   \n           dtg < cast('2020-09-01 00:00' as timestamp) and nav_status_code IN (1,5)\n           \"\"\").write.csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/forecast_2\")"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"select mmsi, dtg, vessel_type_code, vessel_type_cargo, flag_country, destination, eta, draught, longitude, latitude, sog, rot, heading, nav_status_code, nav_status, source, length, message_type, vessel_type_main, vessel_type_sub, eeid from ee where st_intersects(position,st_makeBox2d(st_point(-46.4816,-24.1178),st_point(-46.1763,-23.8787))) AND dtg >= cast('2020-09-01 00:00' as timestamp) order by dtg asc\"\"\").coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/forecast_6\")\n    \n    \n    ", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"select mmsi, dtg, vessel_type_code, vessel_type_cargo, flag_country, destination, eta, draught, longitude, latitude, sog, rot, heading, nav_status_code, nav_status, source, length, message_type, vessel_type_main, vessel_type_sub, eeid from ee where dtg >= cast('2020-09-07 11:00' as timestamp) order by dtg asc\"\"\").coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/forecast_7\")", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"\nSELECT\n    *\nFROM\n(\nSELECT\n    mmsi,\n    (\n        (\n            unix_timestamp(MAX(dtg)) - unix_timestamp('2020-09-07 15:00:00')\n        )/60\n    ) AS last_transmission,\n    max(latitude),\n    max(longitude)\nFROM\n    ee\nWHERE\n    nav_status_code = 0\nand\n    dtg >= cast(('2020-09-07 15:00:00') as timestamp)\nand\n    vessel_type_code IN (\n    '60', '61', '62', '63', '64', '65', '66', '67', '68', '69',\n    '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n    '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n    '90', '91', '92', '93', '94', '95', '96', '97', '98', '99' \n    )\nGROUP BY\n    mmsi\nORDER BY\n    mmsi\nASC\n) t\nWHERE\n    t.last_transmission >= 10\nORDER BY\n    t.last_transmission\nDESC\n\"\"\").coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/rodrigo/transmission\")\n\n# .coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/forecast_7\")", "execution_count": 11, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"\nSELECT\n    round(latitude, 2) as latitude,\n    round(longitude, 2) as longitude,\n    count(mmsi)\nFROM\n    ee\nWHERE\n    message_type IN ('5') \nand\n    dtg >= cast(('2020-09-07 11:00:00') as timestamp)\nand\n    dtg >= cast(('2020-09-07 12:00:00') as timestamp)\ngroup by\n    round(latitude, 2),\n    round(longitude, 2)\norder by\n    round(latitude, 2),\n    round(longitude, 2)\nasc\n\"\"\").show(50)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "An error was encountered:\nInvalid status code '404' from http://ip-10-250-1-253.ec2.internal:8998/sessions/96 with error payload: \"Session '96' not found.\"\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"select count(1),  CAST(dtg AS DATE) FROM\n                (select DISTINCT(mmsi), CAST(dtg AS DATE)\n            from ee where \n           st_intersects(position,st_makeBox2d(st_point(-46.4816,-24.1178),st_point(-46.1763,-23.8787))) AND\n           dtg >= cast('2020-01-01 00:00' as timestamp) and   \n           dtg < cast('2020-09-01 00:00' as timestamp) and nav_status_code = 5 ORDER BY dtg, mmsi)\n           group by dtg order by dtg\"\"\").show(10)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1.write.csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/deb2\")", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "'NoneType' object has no attribute 'write'\nTraceback (most recent call last):\nAttributeError: 'NoneType' object has no attribute 'write'\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"select \nposition from ee where \n           st_intersects(position,st_makeBox2d(st_point(-46.4816,-24.1178),st_point(-46.1763,-23.8787))) AND\n           dtg >= cast('2020-02-01 00:00' as timestamp) and   \n           dtg < cast('2020-02-02 00:00' as timestamp) \"\"\").show(10)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1.write.csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/td\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"select * from ee where \n           st_intersects(position,st_makeBox2d(st_point(-46.4816,-24.1178),st_point(-46.1763,-23.8787))) AND\n           dtg > cast('2019-01-01 00:00' as timestamp) and   \n           dtg < cast('2019-01-02 00:00' as timestamp) AND (mmsi = 356347000) order by dtg\"\"\")\n\nmmsi,imo,dtg,vessel_name,callsign,vessel_type,vessel_type_code,\nvessel_type_cargo,vessel_class,length,width,flag_country,flag_code,destination,eta,\ndraught,position,longitude,latitude,sog,cog,rot,heading,nav_status,nav_status_code,source,\nts_pos_utc,ts_static_utc,dt_pos_utc,dt_static_utc,vessel_type_main,vessel_type_sub,message_type,eeid ", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "!hdfs dfs -ls /", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.coalesce(1).write.csv(\"/myresults.csv\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#result set will be very large, show only 10 results for this example\nspark.sql(\"\"\" select dt_pos_utc, mmsi, vessel_name, longitude, latitude \n                FROM ee WHERE mmsi = 366206000 AND dt_pos_utc > date_add(current_timestamp(), -1) \"\"\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sparkContext.applicationId", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "### m\u00e9dia de velocidade\ndf1=spark.sql(\"\"\" SELECT longitude, SUM(sog)/COUNT(*) \n                    FROM ee WHERE \n                    st_intersects(position,st_makeBox2d(st_point(-46,-20),st_point(15,-25))) \n                    AND dtg >= cast('2020-09-01' as DATE) \n                    group by longitude order by longitude\"\"\").show(10)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}