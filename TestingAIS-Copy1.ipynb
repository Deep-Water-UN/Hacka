{"cells": [{"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "import geomesa_pyspark \nconf = geomesa_pyspark.configure(jars=['/usr/lib/spark/jars/geomesa-hbase-spark-runtime_2.11-2.1.0-m.2.jar'],\n                                 packages=['geomesa_pyspark','pytz'], \n                                 spark_home='/usr/lib/spark/') \n#setAppName('MyTestApp')\nconf.get('spark.master') # u'yarn'\nfrom pyspark.sql import SparkSession\nspark = ( SparkSession.builder.config(conf=conf).getOrCreate() )\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>78</td><td>application_1599127947832_0079</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-250-1-253.ec2.internal:20888/proxy/application_1599127947832_0079/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-250-1-212.ec2.internal:8042/node/containerlogs/container_1599127947832_0079_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "params = {    \"hbase.zookeepers\": \"hbase.optix-ons-local:2181\",    \"hbase.catalog\": \"ons-historical\" } \nfeature = \"ee\" \nee = ( spark    .read    .format(\"geomesa\")    .options(**params)    .option(\"geomesa.feature\", feature)    .load() )\nee.createOrReplaceTempView(\"ee\")\n", "execution_count": 5, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\" select dtg, vessel_name, message_type from ee where \n           st_intersects(position,st_makeBox2d(st_point(-46.481607,-24.1178),st_point(-46.1763,-23.8787))) AND\n           dtg > cast('2020-09-01 00:00' as timestamp) AND message_type = 12 \"\"\").coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/dados\")\n", "execution_count": 6, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}