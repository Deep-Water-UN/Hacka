{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import geomesa_pyspark \nconf = geomesa_pyspark.configure(jars=['/usr/lib/spark/jars/geomesa-hbase-spark-runtime_2.11-2.1.0-m.2.jar'],\n                                 packages=['geomesa_pyspark','pytz'], \n                                 spark_home='/usr/lib/spark/') \n#setAppName('MyTestApp')\nconf.get('spark.master') # u'yarn'\nfrom pyspark.sql import SparkSession\nspark = ( SparkSession.builder.config(conf=conf).getOrCreate() )\n\nparams = {    \"hbase.zookeepers\": \"hbase.optix-ons-local:2181\",    \"hbase.catalog\": \"ons-historical\" } \nfeature = \"ee\" \nee = ( spark    .read    .format(\"geomesa\")    .options(**params)    .option(\"geomesa.feature\", feature)    .load() )\nee.createOrReplaceTempView(\"ee\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"\nSELECT\n    latitude,\n    longitude,\n    mmsi,\n    vessel_type_code,\n    cast(dtg as date)\nFROM\n    ee\nWHERE\n    nav_status_code = '5'\nand\n    vessel_type_code IN (\n    '60', '61', '62', '63', '64', '65', '66', '67', '68', '69',\n    '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n    '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n    '90', '91', '92', '93', '94', '95', '96', '97', '98', '99' \n    )\nand\n    dtg >= cast(('2020-09-01 00:00:00') as timestamp)\nand\n    dtg >= cast(('2020-09-07 00:00:00') as timestamp)\norder by\n    dtg\nasc\n\"\"\").coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/rodrigo/porto_1\")\n\n# .coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/forecast_7\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df1=spark.sql(\"\"\"\nSELECT\n    mmsi,\n    vessel_type_code,\n    dtg,\n    message_type\nFROM\n    ee\nWHERE\n    message_type IN (13, 14)\nand\n    dtg >= cast(('2020-01-01 00:00:00') as timestamp)\nand\n    dtg >= cast(('2020-09-07 00:00:00') as timestamp)\norder by\n    dtg\nasc\n\"\"\").show(10)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}