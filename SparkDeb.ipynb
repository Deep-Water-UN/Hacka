{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Datasets"}, {"metadata": {}, "cell_type": "markdown", "source": "### Configuring the server"}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "import geomesa_pyspark \nconf = geomesa_pyspark.configure(jars=['/usr/lib/spark/jars/geomesa-hbase-spark-runtime_2.11-2.1.0-m.2.jar'],\n                                 packages=['geomesa_pyspark','pytz'], \n                                 spark_home='/usr/lib/spark/') \n#setAppName('MyTestApp')\nconf.get('spark.master') # u'yarn'\nfrom pyspark.sql import SparkSession\nspark = ( SparkSession.builder.config(conf=conf).getOrCreate() )", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>112</td><td>application_1599127947832_0113</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-250-1-253.ec2.internal:20888/proxy/application_1599127947832_0113/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-250-1-193.ec2.internal:8042/node/containerlogs/container_1599127947832_0113_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "params = {    \"hbase.zookeepers\": \"hbase.optix-ons-local:2181\",    \"hbase.catalog\": \"ons-historical\" } \nfeature = \"ee\" \nee = ( spark    .read    .format(\"geomesa\")    .options(**params)    .option(\"geomesa.feature\", feature)    .load() )\nee.createOrReplaceTempView(\"ee\")", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Incident\nIn order to know the wave, there was an indication of communication, we selected the records with message_type equal to 12, 13, or 14, peas, these types specifically identify some type of problem in the vessel. In addition, we selected the time period 2020-06-01, as there is a lot of data from the database and validating all data would be impossible, due to the query processing time. However, finding message_type 12, 13 and 14 is difficult and we were also unable to select a short time or filter by a specific region."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\"\"\" select message_type, latitude, longitude, CAST (dtg AS DATE), count(*) \n                    from ee where \n                    dtg >= cast('2020-07-01' as DATE)\n                    AND (message_type = 12 or message_type = 13 or message_type = 14)\n                    group by dtg, latitude, longitude, message_type order by dtg\"\"\")", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Average speed\nTo find out what the average speed was for a given region, we add all vessel speeds at any latitude in the range (from -20 to -25) and divide by the number of vessel records at longitude,\nso we have the average speed per longitude"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\"\"\" SELECT longitude, SUM(sog)/COUNT(*) \n                    FROM ee WHERE \n                    st_intersects(position,st_makeBox2d(st_point(-46,-20),st_point(15,-25))) \n                    AND dtg >= cast('2020-09-01' as DATE) \n                    group by longitude order by longitude\"\"\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Shadow area\nShadow area is a place where communication does not work well and therefore, it is not possible to send the position record.\nThus, we analyzed the uploaded files in which the time difference between the file's dtg and ts_pos_utc is greater than 10 min.\nIn this query we show which regions are more likely to be a shadow area based on the amount of records that failed to be sent."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\"\"\" SELECT latitude, longitude, COUNT(*)\n                    FROM ee WHERE \n                    st_intersects(position,st_makeBox2d(st_point(-46,-20),st_point(15,25))) \n                    AND dtg >= cast('2020-09-01' as DATE) \n                    AND (minute(dtg) - minute(ts_pos_utc))>= 10\n                    group by latitude, longitude order by longitude\"\"\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Used to save the results in a CSV file\ndf1.coalesce(1).write.option(\"header\", \"true\").csv(\"s3://optix.ons.jupyter/jupyter/dwater/folder/dados\")", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}